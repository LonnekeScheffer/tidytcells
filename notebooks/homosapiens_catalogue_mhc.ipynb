{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catalogue MHC genes (Homo sapiens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if not 'PROJECT_PATH' in globals():\n",
    "    PROJECT_PATH = Path.cwd().parent.resolve()\n",
    "\n",
    "sys.path.append(PROJECT_PATH)\n",
    "os.chdir(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/wmda/hla_nom.txt') as f:\n",
    "    alleles_df = pd.read_csv(f, sep=';', skiprows=6, names=['locus', 'allele', 'assigned', 'deleted', 'identical to', 'reason for deletion'])\n",
    "    alleles_df = alleles_df[alleles_df['locus'].str.endswith('*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/wmda/hla_nom_g.txt') as f:\n",
    "    g_df = pd.read_csv(f, sep=';', skiprows=6, names=['locus', 'allele', 'group'])\n",
    "    g_df = g_df[g_df['locus'].str.endswith('*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen('https://raw.githubusercontent.com/ANHIG/IMGTHLA/Latest/wmda/hla_nom_p.txt') as f:\n",
    "    p_df = pd.read_csv(f, sep=';', skiprows=6, names=['locus', 'allele', 'group'])\n",
    "    p_df = p_df[p_df['locus'].str.endswith('*')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all MHC genes and alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all alleles\n",
    "alleles = alleles_df[alleles_df['deleted'].isna()]\n",
    "alleles = alleles.apply(lambda row: 'HLA-' + row['locus'] + row['allele'], axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all G groups\n",
    "g_groups = g_df[g_df['group'].notna()]\n",
    "g_groups = g_groups.apply(lambda row: 'HLA-' + row['locus'] + row['group'], axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all P groups\n",
    "p_groups = p_df[p_df['group'].notna()]\n",
    "p_groups = p_groups.apply(lambda row: 'HLA-' + row['locus'] + row['group'], axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_hla(gene_str: str, max_spec_field_depth: int = 2):\n",
    "    m = re.match(r'^([A-Z0-9\\-]+)\\*([\\dGP:]+)[LSCAQN]?$', gene_str)\n",
    "\n",
    "    if m is None:\n",
    "        raise ValueError(gene_str)\n",
    "    \n",
    "    gene = m.group(1)\n",
    "    spec_fields = m.group(2).split(':')[:max_spec_field_depth]\n",
    "    \n",
    "    return (gene,) + tuple(spec_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_groups_decomposed = [decompose_hla(g_group, 4) for g_group in g_groups if decompose_hla(g_group, 4) is not None]\n",
    "p_groups_decomposed = [decompose_hla(p_group, 4) for p_group in p_groups if decompose_hla(p_group, 4) is not None]\n",
    "proteins_decomposed = [\n",
    "    decompose_hla(allele) for allele in alleles\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_decomposed = list(\n",
    "    dict.fromkeys(\n",
    "        sorted(g_groups_decomposed + p_groups_decomposed + proteins_decomposed)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hla_tree(current_root: dict, token_lists: list) -> None:\n",
    "    first_tokens = list(\n",
    "        dict.fromkeys(\n",
    "            sorted([token_list[0] for token_list in token_lists])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for token in first_tokens:\n",
    "        current_root[token] = {}\n",
    "\n",
    "        new_token_lists = [\n",
    "            token_list[1:] for token_list in token_lists \\\n",
    "            if token_list[0] == token and \\\n",
    "            len(token_list) > 1\n",
    "        ]\n",
    "\n",
    "        make_hla_tree(current_root[token], new_token_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_tree = {}\n",
    "\n",
    "make_hla_tree(hla_tree, combined_decomposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path('src')/'tidytcells'/'resources'/'homosapiens_mhc.json', 'w') as f:\n",
    "    json.dump(hla_tree, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get deprecated names/synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnc = pd.read_csv(Path('data')/'hgnc.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only MHC genes\n",
    "mhc_genes = hgnc[hgnc['Gene group name'].notna()]\n",
    "mhc_genes = mhc_genes[mhc_genes['Gene group name'].str.contains('Histocompatibility complex')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep genes whose 'approved symbols' are in our IMGT list\n",
    "mhc_genes = mhc_genes[mhc_genes['Approved symbol'].map(lambda x: x in hla_tree)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MHC genes with aliases\n",
    "mhc_genes_with_aliases = mhc_genes[mhc_genes['Alias symbols'].notna()][['Approved symbol', 'Alias symbols']]\n",
    "mhc_genes_with_aliases['Alias symbols'] = mhc_genes_with_aliases['Alias symbols'].map(lambda x: x.split(', '))\n",
    "mhc_genes_with_aliases.columns = ['Approved symbol', 'Synonym']\n",
    "mhc_genes_with_aliases = mhc_genes_with_aliases.explode('Synonym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MHC genes with deprecated names\n",
    "mhc_genes_with_depnames = mhc_genes[mhc_genes['Previous symbols'].notna()][['Approved symbol', 'Previous symbols']]\n",
    "mhc_genes_with_depnames['Previous symbols'] = mhc_genes_with_depnames['Previous symbols'].map(lambda x: x.split(', '))\n",
    "mhc_genes_with_depnames.columns = ['Approved symbol', 'Synonym']\n",
    "mhc_genes_with_depnames = mhc_genes_with_depnames.explode('Synonym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both tables\n",
    "mhc_synonyms = pd.concat([mhc_genes_with_aliases, mhc_genes_with_depnames])\n",
    "\n",
    "# Capitalise synonyms\n",
    "mhc_synonyms['Synonym'] = mhc_synonyms['Synonym'].str.upper()\n",
    "\n",
    "# Group together by synonym\n",
    "mhc_synonyms = mhc_synonyms.groupby('Synonym').aggregate(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard ambiguous synonyms\n",
    "mhc_synonyms = mhc_synonyms[mhc_synonyms['Approved symbol'].map(len) == 1].copy()\n",
    "mhc_synonyms['Approved symbol'] = mhc_synonyms['Approved symbol'].map(lambda x: x.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard redundant items (synonym == approved symbol)\n",
    "mhc_synonyms = mhc_synonyms[mhc_synonyms.index != mhc_synonyms['Approved symbol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhc_synonyms['Approved symbol'].to_json(\n",
    "    Path('src')/'tidytcells'/'resources'/'homosapiens_mhc_synonyms.json',\n",
    "    indent=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9113dead31263b73eafaec25dace067586105dc5705e88fed689dacfad72cc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
